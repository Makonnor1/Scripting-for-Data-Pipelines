{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of tweets from LA for 2022 (in English only) \n",
    "#looking at burgler, crime, theft, assault and murder keywords\n",
    "tweets_list = []\n",
    "\n",
    "#find tweets that include the brand glossier or #glossier\n",
    "query = '''burglary OR burglar OR burglarized OR stolen OR stole until:2017-12-31 since:2017-06-01 lang:en near:\"Los Angeles\"'''\n",
    "\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query=query).get_items()):\n",
    "        if i > 1000: \n",
    "            break\n",
    "        tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-30 21:57:58+00:00</td>\n",
       "      <td>947225272117370880</td>\n",
       "      <td>ðŸš¨ WILSHIRE/FAIRFAX AREA ðŸš¨ Some random man stol...</td>\n",
       "      <td>JennieMelissa</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-30 21:52:41+00:00</td>\n",
       "      <td>947223942955122689</td>\n",
       "      <td>@DevinColson I loved bad ape. Stole all the sc...</td>\n",
       "      <td>The_5th_Turtle</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-30 21:36:21+00:00</td>\n",
       "      <td>947219832440844288</td>\n",
       "      <td>congratulations Dwayne \"The rock\" Johnson's da...</td>\n",
       "      <td>johnlawofficial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-30 20:01:23+00:00</td>\n",
       "      <td>947195935884324864</td>\n",
       "      <td>Thinking about how in the future people could ...</td>\n",
       "      <td>erinyasgar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-30 19:54:50+00:00</td>\n",
       "      <td>947194287313129472</td>\n",
       "      <td>My phone has been stolen. If you need to reach...</td>\n",
       "      <td>kevkrav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date            Tweet Id  \\\n",
       "0 2017-12-30 21:57:58+00:00  947225272117370880   \n",
       "1 2017-12-30 21:52:41+00:00  947223942955122689   \n",
       "2 2017-12-30 21:36:21+00:00  947219832440844288   \n",
       "3 2017-12-30 20:01:23+00:00  947195935884324864   \n",
       "4 2017-12-30 19:54:50+00:00  947194287313129472   \n",
       "\n",
       "                                                Text             User  Likes  \\\n",
       "0  ðŸš¨ WILSHIRE/FAIRFAX AREA ðŸš¨ Some random man stol...    JennieMelissa      3   \n",
       "1  @DevinColson I loved bad ape. Stole all the sc...   The_5th_Turtle      1   \n",
       "2  congratulations Dwayne \"The rock\" Johnson's da...  johnlawofficial      0   \n",
       "3  Thinking about how in the future people could ...       erinyasgar      0   \n",
       "4  My phone has been stolen. If you need to reach...          kevkrav      1   \n",
       "\n",
       "   Retweets  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.DataFrame(tweets_list, columns=['Date', 'Tweet Id', 'Text', 'User', 'Likes', 'Retweets'])\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all hashtags and @ mentions used\n",
    "hashtag_list = []\n",
    "\n",
    "for tweet in tweets_list:\n",
    "    for word in tweet[2].split():\n",
    "        if word.startswith('#'):\n",
    "            hashtag_list.append(word)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find counts of each hashtags and sort them by most used\n",
    "unique_hashtags = []\n",
    "hashtag_counts = []\n",
    "\n",
    "for word in hashtag_list:\n",
    "    count = 0\n",
    "    if word in unique_hashtags:\n",
    "        continue\n",
    "    else:\n",
    "        for w in hashtag_list:\n",
    "            if word == w:\n",
    "                count = count+1\n",
    "            else:\n",
    "                continue\n",
    "        unique_hashtags.append(word)\n",
    "        dict = {}\n",
    "        dict['hashtag'] = word\n",
    "        dict['count'] = count\n",
    "        hashtag_counts.append(dict)\n",
    "\n",
    "sorted_hashtags = sorted(hashtag_counts, key = lambda d: d['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtag: #Topbuzz Count 4\n",
      "Hashtag: #Christmas Count 4\n",
      "Hashtag: #Repost Count 4\n",
      "Hashtag: #stolen Count 3\n",
      "Hashtag: #christmas Count 3\n",
      "Hashtag: #grinch Count 3\n",
      "Hashtag: #CharlesManson Count 3\n",
      "Hashtag: #LoveTrumpsHate Count 3\n",
      "Hashtag: # Count 2\n",
      "Hashtag: #Grinch Count 2\n"
     ]
    }
   ],
   "source": [
    "#print the top 10 hashtags\n",
    "for hashtag in sorted_hashtags[:10]:\n",
    "    print('Hashtag:', hashtag['hashtag'], 'Count', hashtag['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the Text Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27203"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "msglist = tweets_df['Text']\n",
    "all_tokens = [tok for msg in msglist for tok in nltk.word_tokenize(msg)]\n",
    "len(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ðŸš¨',\n",
       " 'WILSHIRE/FAIRFAX',\n",
       " 'AREA',\n",
       " 'ðŸš¨',\n",
       " 'Some',\n",
       " 'random',\n",
       " 'man',\n",
       " 'stole',\n",
       " 'my',\n",
       " 'friends']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first 10 tokens\n",
    "all_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make tokens all lowercase\n",
    "all_tokens = [tok.lower() for msg in msglist for tok in nltk.word_tokenize(msg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Samantha\n",
      "[nltk_data]     White\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of stopwords\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wilshire/fairfax',\n",
       " 'area',\n",
       " 'random',\n",
       " 'man',\n",
       " 'stole',\n",
       " 'friends',\n",
       " 'dog',\n",
       " 'peddles',\n",
       " 'please',\n",
       " 'keep']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stopwords from conversation and non keywords\n",
    "import re\n",
    "def alpha_filter(w):\n",
    "    pattern = re.compile('^[^a-z]+$') \n",
    "    if (pattern.match(w)): \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "t_list = [tok for tok in all_tokens if not alpha_filter(tok)]\n",
    "\n",
    "token_list = []\n",
    "for tok in t_list:\n",
    "    if tok in nltk_stopwords:\n",
    "        continue\n",
    "    else: \n",
    "        token_list.append(tok)\n",
    "token_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stole 641\n",
      "https 422\n",
      "stolen 356\n",
      "christmas 105\n",
      "amp 86\n",
      "'s 80\n",
      "car 77\n",
      "got 72\n",
      "someone 70\n",
      "one 67\n",
      "n't 67\n",
      "like 65\n",
      "grinch 64\n",
      "get 50\n",
      "time 43\n",
      "people 41\n",
      "heart 40\n",
      "back 38\n",
      "money 36\n",
      "show 34\n",
      "us 32\n",
      "man 31\n",
      "shit 29\n",
      "night 28\n",
      "right 28\n",
      "new 28\n",
      "last 28\n",
      "know 28\n",
      "good 27\n",
      "really 27\n"
     ]
    }
   ],
   "source": [
    "#find 30 most common words\n",
    "msgFD = nltk.FreqDist(token_list) \n",
    "top_words = msgFD.most_common(30) \n",
    "for word, freq in top_words: \n",
    "    print(word, freq) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords to point out:\n",
    "Christmas, Money, Car, Man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
